<h1><u>Tag Analysis</u></h1>

<div class="jumbotron" id="tar1">
	<h4>
		<p>
			This image-- <b>HPIM1017.jpg</b> --performed significantly better with Azure than it did with A.W.S.; 
		</p>
		<br>
		<p>
			<b>Azure</b> was able to recognize that this was a woman who was outside, standing on the street, while <b>A.W.S.</b> generated tags that suggest that she's a plant, tree or potted plant. 
		</p>

	</h4>

</div>

<div class="jumbotron" id="tar2">
	<h4>
		<p>
			This image-- <b>HPIM1020.jpg</b> -- provided better results for A.W.S. 
		</p>
		<br>
		<p>
			<b>Azure</b> identified a group of people who were posing in a picture; it, also, noticed that one person in the photo was wearing a suit. <b>A.W.S.</b> was able to recognize the young man's suit. 
		</p>

	</h4>

</div>

<div class="jumbotron" id="tar3">
	<h4>
		<p>
			This image-- <b>HPIM1022.jpg</b> --generated tags in A.W.S. that might be impacted by a language barrier; 
		</p>
		<br>
		<p>
			<b>Azure</b> generated similar tags as it did for HPIM1020., "suit", "posing", "people_group".<b>A.W.S.</b> produced "wedding_robe", "gown", "selfie"--we weren't significantly impressed by these results. 
		</p>

	</h4>

</div>

<div class="jumbotron" id="tar4">
	<h4>
		<p>
			This image,-- <b>HPIM1038.jpg</b> -- A.W.S. results labels were quite underwhelming; I don't, honestly, understand why it focused on the table. It could be useful, depending on the usecase... 
		</p>
		<br>
		<p>
			<b>Azure</b> produced results which identified this couple as being indoors and posing, while <b>A.W.S.</b> generated tags that focused on the table behind the couple; it provided: "furniture", "dining_table", and "table".  
		</p>

	</h4>

</div>

<div class="jumbotron" id="tar5">
	<h4>
		<p>
			This image-- <b>HPIM1017.jpg</b> --produced a somewhat better result with Azure. A.W.S. labels were very limited; It didn't focus on the young women in the photo. 
		</p>
		<br>
		<p>
			<b>Azure</b> recognized group and crowd tags,  while <b>A.W.S.</b> generated a "selfie" and "night_life" label. Both results were about par. 
		</p>

	</h4>

</div>

<div class="jumbotron" id="tar6">
	<h4>
		<p>
			This image-- <b>HPIM1017.jpg</b> --performed better with Azure than it did with A.W.S.; Azure tags were more relevant. 
		</p>
		<br>
		<p>
			<b>Azure</b> was able to recognize that this was a group of people posing for a picture. <b>A.W.S.</b> did not generate any useful tag results; "shirt", "selfie" and "clothing" don't seem at all useful. 
		</p>

	</h4>

</div>

<div class="jumbotron" id="tar7">
	<h4>
		<p>
			This image-- <b>HPIM1017.jpg</b> --performed slightly better with Azure than it did with A.W.S.; 
		</p>
		<br>
		<p>
			<b>Azure</b> provided "spactacles", while <b>A.W.S.</b> generated "selfie". Nither results were breath taking. Although, the spectacle was a bit more relevant and intuitive; even though, the language choice is not the greatest.
		</p>

	</h4>

</div>
<h2>Emotion API Results</h2>
<br>
<div class="jumbotron" id="tar8">
	<h4>
		<p>
			The API identifies the photo, <b>“Trump 2016”</b> as a mix of anger and disgust. I was expecting more anger; anger was the highest percentage, but I was expecting it to score higher.
		</p>
		<br>
		<p>
			<b>
	  "anger": 0.28602,

      "contempt": 0.008315658,

      "disgust": 0.221216187,

      "fear": 0.06252582,

      "happiness": 0.0510859936,

      "neutral": 0.136847049,

      "sadness": 0.167110741,

      "surprise": 0.0668785349
      </b>

		</p>

	</h4>

</div>

<div class="jumbotron" id="tar9">
	<h4>
		<p>
			<b>“Don’t make me angry”</b> was accurate, but not very realistic. The photo is extremely intense; most photos would not be this intentionally angry. It did recognize that he was angry. Here is the JSON:
		</p>
		<br>
		<p>
			<b>
	  "anger": 0.999989152,
      "contempt": 3.27815858e-10,
      "disgust": 7.578268e-7,
      "fear": 0.000009156357,
      "happiness": 1.29796078e-11,
      "neutral": 9.545715e-8,
      "sadness": 1.06041753e-8,
      "surprise": 8.26523035e-7
      		</b>

		</p>

	</h4>

</div>


<div class="jumbotron" id="tar10">
	<h4>
		<p>
			<b>“Disgusted”</b> was not accurate; I would think that the disgust would be higher; neutral shouldn’t be the highest percentage.
		</p>
		<br>
		<p>
			<b>
	  "anger": 0.0798403546,
      "contempt": 0.05259169,
      "disgust": 0.240128875,
      "fear": 0.00700049149,
      "happiness": 0.03277454,
      "neutral": 0.315023661,
      "sadness": 0.2590964,
      "surprise": 0.0135439914
      		</b>

		</p>

	</h4>

</div>

<div class="jumbotron" id="tar11">
	<h4>
		<p>
			<b>“Sadness”</b> seems to work well. It did a great job of measuring this little angel’s emotion in the photo.
		</p>
		<br>
		<p>
			<b>
	  "anger": 7.03547755e-7,
      "contempt": 0.0000037830132,
      "disgust": 0.0000049815626,
      "fear": 0.00000245370347,
      "happiness": 0.000145445767,
      "neutral": 0.000182542644,
      "sadness": 0.99966,
      "surprise": 7.92260764e-8
      		</b>

		</p>

	</h4>

</div>

<div class="jumbotron" id="tar12">
	<h4>
		<p>
			<b>“Fear”</b> was recognized pretty accurately. With a confidence level of 66%, fear is the dominant emotion returned, followed by surprise.
		</p>
		<br>
		<p>
			<b>
	  "anger": 0.00123003952,
      "contempt": 0.00033124414,
      "disgust": 0.000800540147,
      "fear": 0.6556605,
      "happiness": 0.000327111629,
      "neutral": 0.04495071,
      "sadness": 0.06618306,
      "surprise": 0.230516762
      		</b>

		</p>

	</h4>

</div>

<div class="jumbotron" id="tar13">
	<h4>
		<p>
			<b>“Surprise”</b> gave surprise in its results; with nearly 100 confidence, this little guy is shocked and surprised.
		</p>
		<br>
		<p>
			<b>
	  "anger": 2.53435843e-7,
      "contempt": 9.313816e-9,
      "disgust": 8.436481e-8,
      "fear": 0.00004662257,
      "happiness": 1.810422e-8,
      "neutral": 0.0000396454161,
      "sadness": 1.2707244e-7,
      "surprise": 0.9999132
      		</b>

		</p>

	</h4>

</div>

<div class="jumbotron" id="tar14">
	<h4>
		<p>
			<b>“Contempt”</b> is a hard emotion to identify, but it was able to recognize it with a 43% accuracy, followed in second by disgust. This is a good result, I think.
		</p>
		<br>
		<p>
			<b>
	  "anger": 0.08671725,
      "contempt": 0.426464349,
      "disgust": 0.195833951,
      "fear": 0.000352131668,
      "happiness": 0.08345109,
      "neutral": 0.189094931,
      "sadness": 0.00519613735,
      "surprise": 0.0128901554
      		</b>

		</p>

	</h4>

</div>



